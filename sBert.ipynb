{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c041b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer,  SentencesDataset, LoggingHandler, losses, util, InputExample, models\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df78aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac455beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59428a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = BertModel.from_pretrained(model_name_or_path, add_pooling_layer=False)\\ntokenizer = BertTokenizer.from_pretrained(model_name_or_path)\\n\\n\\nmodel_name = \"kpfbert-base\"\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"C:/Users/EDU_NH_SNU/kpfbert\"  # Bert 바이너리가 포함된 디렉토리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50f17663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/EDU_NH_SNU/kpfbert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at C:/Users/EDU_NH_SNU/kpfbert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 16\n",
    "word_embedding_model =models.Transformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d1aff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4627c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:41:32 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173d7a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:41:33 - Read AllNLI train dataset\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Read AllNLI train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14a9c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34f06720",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KorNLUDatasets\\kpfSBERT\\KorNLUDatasets\\KorNLI/snli_1.0_train.ko.tsv', \"rt\", encoding=\"utf-8\") as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, label = line.split('\\t')\n",
    "        label = label2int[label.strip()]\n",
    "        train_samples.append(InputExample(texts=[s1, s2], label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c2733a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:50:20 - Softmax loss: #Vectors concatenated: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = SentencesDataset(train_samples, model=model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d969e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:50:20 - Read STSbenchmark dev dataset\n"
     ]
    }
   ],
   "source": [
    "#Read STSbenchmark dataset and use it as development set\n",
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "dev_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80d00a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('KorNLUDatasets\\kpfSBERT\\KorNLUDatasets\\KorSTS/tune_dev.tsv', 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        dev_samples.append(InputExample(texts= [s1,s2], label=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a71b4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, batch_size=train_batch_size, name='sts-dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff836f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-29 11:51:19 - Warmup-steps: 3439\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54464f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca55d0fa7204a59a5de81e29e747634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c912a645104c3db1f1fca09e4658ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/34385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=dev_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "#           output_path=model_save_path\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a894afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('output/kpfSBERT_nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703daecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 4\n",
    "model_save_path = 'output/kpfSBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1cc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Read STSbenchmark train dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "with open('KorNLUDatasets/KorSTS/tune_dev.tsv', 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        dev_samples.append(InputExample(texts= [s1,s2], label=score))\n",
    "\n",
    "with open('KorNLUDatasets/KorSTS/tune_test.tsv', 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        test_samples.append(InputExample(texts= [s1,s2], label=score))\n",
    "\n",
    "with open('KorNLUDatasets/KorSTS/tune_train.tsv', 'rt', encoding='utf-8') as fIn:\n",
    "    lines = fIn.readlines()\n",
    "    for line in lines:\n",
    "        s1, s2, score = line.split('\\t')\n",
    "        score = score.strip()\n",
    "        score = float(score) / 5.0\n",
    "        train_samples.append(InputExample(texts= [s1,s2], label=score))\n",
    "\n",
    "train_dataset = SentencesDataset(train_samples, model)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development set: Measure correlation between cosine score and gold labels\n",
    "logging.info(\"Read STSbenchmark dev dataset\")\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b401937",
   "metadata": {},
   "outputs": [],
   "source": [
    " TEST1 : sentesce similarity sorting with cosine similarity\n",
    "\n",
    "model_path = model_save_path\n",
    "\n",
    "model = SentenceTransformer(model_path)\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['한 남자가 음식을 먹는다.',\n",
    "          '한 남자가 빵 한 조각을 먹는다.',\n",
    "          '그 여자가 아이를 돌본다.',\n",
    "          '한 남자가 말을 탄다.',\n",
    "          '한 여자가 바이올린을 연주한다.',\n",
    "          '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "          '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    "          '원숭이 한 마리가 드럼을 연주한다.',\n",
    "          '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['한 남자가 파스타를 먹는다.',\n",
    "           '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "           '치타가 들판을 가로 질러 먹이를 쫓는다.']\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    #We use np.argpartition, to only partially sort the top_k results\n",
    "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx in top_results[0:top_k]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba93e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST2 : Clustering with k-means\n",
    "\n",
    "model_path = model_save_path\n",
    "\n",
    "model = SentenceTransformer(model_path)\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['한 남자가 음식을 먹는다.',\n",
    "          '한 남자가 빵 한 조각을 먹는다.',\n",
    "          '그 여자가 아이를 돌본다.',\n",
    "          '한 남자가 말을 탄다.',\n",
    "          '한 여자가 바이올린을 연주한다.',\n",
    "          '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "          '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    "          '원숭이 한 마리가 드럼을 연주한다.',\n",
    "          '치타 한 마리가 먹이 뒤에서 달리고 있다.',\n",
    "          '한 남자가 파스타를 먹는다.',\n",
    "          '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "          '치타가 들판을 가로 질러 먹이를 쫓는다.']\n",
    "\n",
    "corpus_embeddings = model.encode(corpus)\n",
    "\n",
    "# Then, we perform k-means clustering using sklearn:\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
